{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19db10f-96fb-4abc-8f4b-e3aef7d65814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 92], x=[27, 3], y=[1])\n",
      "Epoch 0: Loss = 1.0261\n",
      "Epoch 10: Loss = 0.6785\n",
      "Epoch 20: Loss = 0.6707\n",
      "Epoch 30: Loss = 0.6589\n",
      "Epoch 40: Loss = 0.6569\n",
      "Epoch 50: Loss = 0.6536\n",
      "Epoch 60: Loss = 0.6494\n",
      "Epoch 70: Loss = 0.6428\n",
      "Epoch 80: Loss = 0.6339\n",
      "Epoch 90: Loss = 0.6266\n",
      "Epoch 100: Loss = 0.6258\n",
      "Epoch 110: Loss = 0.6252\n",
      "Epoch 120: Loss = 0.6248\n",
      "Epoch 130: Loss = 0.6247\n",
      "Epoch 140: Loss = 0.6246\n",
      "Epoch 150: Loss = 0.6244\n",
      "Epoch 160: Loss = 0.6243\n",
      "Epoch 170: Loss = 0.6242\n",
      "Epoch 180: Loss = 0.6241\n",
      "Epoch 190: Loss = 0.6240\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GAE, GCNConv\n",
    "import networkx as nx\n",
    "# 将边索引转换为 scipy 稀疏矩阵\n",
    "import community as community_louvain  # Louvain community detection\n",
    "from torch_geometric.datasets import Planetoid, TUDataset\n",
    "from torch_geometric.utils import to_dense_adj, to_scipy_sparse_matrix, from_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import community\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "class GraphAutoencoder(GAE):\n",
    "    def __init__(self, encoder):\n",
    "        super(GraphAutoencoder, self).__init__(encoder)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "dataset = TUDataset(root='../tmp/Proteins', name='PROTEINS')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[1].to(device)\n",
    "print(data)\n",
    "edge_index = data.edge_index.cpu().numpy()\n",
    "num_nodes = data.num_nodes\n",
    "G = nx.Graph()#创建networkx的空图\n",
    "for i in range(num_nodes):\n",
    "    G.add_node(i, features=data.x[i].cpu().numpy())\n",
    "# 添加边\n",
    "for i, j in edge_index.T:\n",
    "    G.add_edge(i, j)\n",
    "encoder = Encoder(in_channels=data.x.size(1), hidden_channels=16)\n",
    "model = GraphAutoencoder(encoder)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    adj = torch.matmul(z, z.t())  # Approximate adjacency matrix\n",
    "    adj_pos = torch.zeros_like(adj)\n",
    "    adj_pos[data.edge_index[0], data.edge_index[1]] = 1\n",
    "\n",
    "    # Compute the loss (Binary Cross Entropy Loss for link prediction)\n",
    "    loss = nn.BCEWithLogitsLoss()(adj.view(-1), adj_pos.view(-1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f'Epoch {epoch}: Loss = {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d5d4e2-50b2-4224-a8e9-c3ec19806a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Autoencoder + KMeans clustering modularity: 0.5073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "num_clusters = 5  # You can choose a different number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "clusters = kmeans.fit_predict(z.detach().numpy())\n",
    "\n",
    "# Create node to community mapping\n",
    "node_cluster_map = {node: clusters[i] for i, node in enumerate(G.nodes())}\n",
    "\n",
    "# Convert node to community mapping to a list of communities\n",
    "communities_kmeans = []\n",
    "for community_id in set(node_cluster_map.values()):\n",
    "    communities_kmeans.append([node for node in node_cluster_map if node_cluster_map[node] == community_id])\n",
    "\n",
    "# Compute modularity\n",
    "modularity_kmeans = community.modularity(G, communities_kmeans)\n",
    "print(f\"Graph Autoencoder + KMeans clustering modularity: {modularity_kmeans:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60a778-6369-45fa-85d3-edc40ad51ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
