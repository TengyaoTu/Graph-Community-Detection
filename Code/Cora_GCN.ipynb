{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf2be6f-3eb5-43ab-b3e1-8aed522580f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "from torch_geometric.nn import TransformerConv  # Import the Graph Transformer layer\n",
    "class GCN_NET(torch.nn.Module):\n",
    "    def __init__(self, nhid, nout, dropout):\n",
    "        super().__init__()\n",
    "        #self.conv1 = GCNConv(data.num_node_features, nhid)\n",
    "        #self.conv2 = GCNConv(nhid,nout)\n",
    "        #self.conv1 = TransformerConv(data.num_node_features, nhid, heads=4)  # You can adjust the number of heads\n",
    "        #self.conv2 = TransformerConv(nhid * 4, nout)  # Output feat\n",
    "        #self.conv1 = SAGEConv(data.num_node_features, nhid)\n",
    "        #self.conv2 = SAGEConv(nhid, nout)\n",
    "        #self.conv1 = GATConv(data.num_node_features,  nhid)  # 多头注意力机制\n",
    "        #self.conv2 = GATConv( nhid , nout)  # 最后一层注意力机制，使用单个头\n",
    "        #self.conv1 = TransformerConv(data.num_node_features, nhid, heads=4)  # You can adjust the number of heads\n",
    "        #self.conv2 = TransformerConv(nhid * 4, nout)  # Output feat\n",
    "        self.dropout = dropout\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x,self.dropout , training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "def cluster(data, k, temp, num_iter, init = None, cluster_temp=5):\n",
    "    '''\n",
    "    pytorch (differentiable) implementation of soft k-means clustering.\n",
    "    '''\n",
    "    #normalize x so it lies on the unit sphere\n",
    "    data = torch.diag(1./torch.norm(data, p=2, dim=1)) @ data\n",
    "    #use kmeans++ initialization if nothing is provided\n",
    "    if init is None:\n",
    "        data_np = data.detach().numpy()\n",
    "        norm = (data_np**2).sum(axis=1)\n",
    "        init = sklearn.cluster.k_means_._k_init(data_np, k, norm, sklearn.utils.check_random_state(None))\n",
    "        init = torch.tensor(init, requires_grad=True)\n",
    "        if num_iter == 0: return init\n",
    "    mu = init\n",
    "    n = data.shape[0]\n",
    "    d = data.shape[1]\n",
    "#    data = torch.diag(1./torch.norm(data, dim=1, p=2))@data\n",
    "    for t in range(num_iter):\n",
    "        #get distances between all data points and cluster centers\n",
    "#        dist = torch.cosine_similarity(data[:, None].expand(n, k, d).reshape((-1, d)), mu[None].expand(n, k, d).reshape((-1, d))).reshape((n, k))\n",
    "        dist = data @ mu.t()\n",
    "        #cluster responsibilities via softmax\n",
    "        r = torch.softmax(cluster_temp*dist, 1)\n",
    "        #total responsibility of each cluster\n",
    "        cluster_r = r.sum(dim=0)\n",
    "        #mean of points in each cluster weighted by responsibility\n",
    "        cluster_mean = (r.t().unsqueeze(1) @ data.expand(k, *data.shape)).squeeze(1)\n",
    "        #update cluster means\n",
    "        new_mu = torch.diag(1/cluster_r) @ cluster_mean\n",
    "        mu = new_mu\n",
    "    dist = data @ mu.t()\n",
    "    r = torch.softmax(cluster_temp*dist, 1)\n",
    "    return mu, r, dist\n",
    "\n",
    "class GCNClusterNet(torch.nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nout, dropout, K, cluster_temp):\n",
    "        super(GCNClusterNet, self).__init__()\n",
    "        self.GCN_NET = GCN_NET(nhid, nout, dropout)\n",
    "        self.distmult = torch.nn.Parameter(torch.rand(nout))\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.K = K\n",
    "        self.cluster_temp = cluster_temp\n",
    "        self.init = torch.rand(self.K, nout)\n",
    "\n",
    "    def forward(self,x,adj, num_iter=1):\n",
    "    \t#这里的x，adj没有用，为了方便对比本人把它们作为参数加了进来\n",
    "        embeds = self.GCN_NET(data)\n",
    "        mu_init, _, _ = cluster(embeds, self.K, 1, num_iter, cluster_temp=self.cluster_temp, init=self.init)\n",
    "        mu, r, dist = cluster(embeds, self.K, 1, 1, cluster_temp=self.cluster_temp, init=mu_init.detach().clone())\n",
    "        return mu, r, embeds, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43919a8a-60a4-4cac-8192-73f2ef52dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_modularity_matrix(adj):\n",
    "    adj = adj * (torch.ones(adj.shape[0], adj.shape[0]) - torch.eye(adj.shape[0]))\n",
    "    degrees = adj.sum(axis=0).unsqueeze(1)\n",
    "    mod = adj - degrees @ degrees.t() / adj.sum()\n",
    "    return mod\n",
    "\n",
    "\n",
    "def loss_modularity(r, bin_adj, mod):\n",
    "    bin_adj_nodiag = bin_adj * (torch.ones(bin_adj.shape[0], bin_adj.shape[0]) - torch.eye(bin_adj.shape[0]))\n",
    "    return (1. / bin_adj_nodiag.sum()) * (r.t() @ mod @ r).trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ab26c0-54fb-4b76-9614-52a966613814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "Modularity: 0.8149844040790168\n",
      "Number of communities: 105\n",
      "torch.Size([2708, 105])\n",
      "Updated data:\n",
      "Data(x=[2708, 1538], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "# 将边索引转换为 scipy 稀疏矩阵\n",
    "import community as community_louvain  # Louvain community detection\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_dense_adj, to_scipy_sparse_matrix, from_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "dataset = Planetoid(root='../tmp/Cora', name='Cora')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "print(data)\n",
    "def enhance_data(data):\n",
    "    edge_index = data.edge_index.cpu().numpy()\n",
    "    num_nodes = data.num_nodes\n",
    "    G = nx.Graph()#创建networkx的空图\n",
    "    for i in range(num_nodes):\n",
    "        G.add_node(i, features=data.x[i].cpu().numpy())\n",
    "    # 添加边\n",
    "    for i, j in edge_index.T:\n",
    "        G.add_edge(i, j)\n",
    "    partition = community_louvain.best_partition(G)\n",
    "    # 计算模块度\n",
    "    modularity = community_louvain.modularity(partition, G)\n",
    "    print(f\"Modularity: {modularity}\")\n",
    "    # 计算社区数量\n",
    "    num_communities = len(set(partition.values()))\n",
    "    print(f\"Number of communities: {num_communities}\")\n",
    "    node_embeddings = np.zeros((len(partition), num_communities))\n",
    "    for node, community in partition.items():\n",
    "        node_embeddings[node, community] = 1\n",
    "    # 转换为 PyTorch 张量\n",
    "    node_embeddings_tensor = torch.tensor(node_embeddings, dtype=torch.float)\n",
    "    print(np.shape(node_embeddings_tensor))\n",
    "    # 拼接原特征和独热编码特征\n",
    "    original_features = data.x.cpu().numpy()  # 获取原始特征，并转换为 numpy 数组\n",
    "    combined_features = np.hstack((original_features, node_embeddings))  # 拼接特征\n",
    "    combined_features_tensor = torch.tensor(combined_features, dtype=torch.float).to(device)  # 转换为 PyTorch 张量\n",
    "    # 更新 data 对象中的特征\n",
    "    data.x = combined_features_tensor\n",
    "    return data\n",
    "data=enhance_data(data)\n",
    "print(\"Updated data:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5154666d-b369-4ef4-9cc9-09dda897ebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1538], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "torch.Size([2708, 2708])\n"
     ]
    }
   ],
   "source": [
    "##获得数据集的data\n",
    "# 将 edge_index 转换为稠密的邻接矩阵\n",
    "print(data)\n",
    "adj = to_dense_adj(data.edge_index)[0]\n",
    "def normalize(mx):\n",
    "    rowsum = np.array(mx.sum(1))  # 矩阵行求和\n",
    "    r_inv = np.power(rowsum, -1).flatten()  # 每行和的-1次方\n",
    "    r_inv[np.isinf(r_inv)] = 0.  # 如果是inf，转换为0\n",
    "    r_mat_inv = sp.diags(r_inv)  # 转换为对角阵\n",
    "    mx = r_mat_inv.dot(mx)  # D-1*A,乘上特征，按行归一化\n",
    "    return mx\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "features = sp.csr_matrix(data.x, dtype=np.float32)  # 取特征\n",
    "\n",
    "adj = sp.coo_matrix((np.ones(data.edge_index.shape[1]), (data.edge_index[0, :], data.edge_index[1, :])),\n",
    "                    shape=(data.y.shape[0], data.y.shape[0]), dtype=np.float32)\n",
    "\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "features = normalize(features)  # 特征归一化\n",
    "adj = normalize(adj + sp.eye(adj.shape[0]))  # A+I归一化\n",
    "features = torch.FloatTensor(np.array(features.todense()))# 将numpy的数据转换成torch格式\n",
    "adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "adj = adj.coalesce()\n",
    "\n",
    "bin_adj_all = (adj.to_dense() > 0).float()\n",
    "print(np.shape(bin_adj_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cb46540-1bdf-4961-9f35-151c2360cbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1   ClusterNet value:0.2745811641216278\n",
      "epoch101   ClusterNet value:0.7316926121711731\n",
      "epoch201   ClusterNet value:0.7321180105209351\n",
      "epoch301   ClusterNet value:0.7331862449645996\n",
      "epoch401   ClusterNet value:0.7341327667236328\n",
      "epoch501   ClusterNet value:0.7514181137084961\n",
      "epoch601   ClusterNet value:0.7533242702484131\n",
      "epoch701   ClusterNet value:0.7533242702484131\n",
      "epoch801   ClusterNet value:0.7533242702484131\n",
      "epoch901   ClusterNet value:0.7533242702484131\n",
      "epoch1001   ClusterNet value:0.7533242702484131\n",
      "epoch1101   ClusterNet value:0.7533242702484131\n",
      "epoch1201   ClusterNet value:0.7533242702484131\n",
      "epoch1301   ClusterNet value:0.7533242702484131\n",
      "epoch1401   ClusterNet value:0.7533242702484131\n",
      "epoch1501   ClusterNet value:0.7533242702484131\n",
      "epoch1601   ClusterNet value:0.7533242702484131\n",
      "epoch1701   ClusterNet value:0.7533242702484131\n",
      "epoch1801   ClusterNet value:0.7533242702484131\n",
      "epoch1901   ClusterNet value:0.7533242702484131\n",
      "epoch2001   ClusterNet value:0.7533242702484131\n"
     ]
    }
   ],
   "source": [
    "model_cluster = GCNClusterNet(nfeat=1537, nhid=50, nout=50, dropout=0.2, K=7, cluster_temp=50)\n",
    "bin_adj_all = (adj.to_dense() > 0).float()\n",
    "optimizer = torch.optim.Adam(model_cluster.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "test_object = make_modularity_matrix(bin_adj_all)\n",
    "model_cluster.train()\n",
    "num_cluster_iter = 1\n",
    "losses = []\n",
    "GCN_value=[]\n",
    "for epoch in range(2001):\n",
    "    mu, r, embeds, dist = model_cluster(features, adj, num_cluster_iter)\n",
    "    loss = loss_modularity(r, bin_adj_all, test_object)\n",
    "    loss = -loss\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    if epoch == 500:\n",
    "        num_cluster_iter = 5\n",
    "    if epoch % 100 == 0:\n",
    "        r = torch.softmax(100 * r, dim=1)\n",
    "    loss_test = loss_modularity(r, bin_adj_all, test_object)\n",
    "    if epoch == 0:\n",
    "        best_train_val = 100\n",
    "    if loss.item() < best_train_val:\n",
    "        best_train_val = loss.item()\n",
    "        curr_test_loss = loss_test.item()\n",
    "        # convert distances into a feasible (fractional x)#将距离转换为可行的（分数x）\n",
    "        x_best = torch.softmax(dist * 100, 0).sum(dim=1)\n",
    "        x_best = 2 * (torch.sigmoid(4 * x_best) - 0.5)\n",
    "        if x_best.sum() > 5:\n",
    "            x_best = 5 * x_best / x_best.sum()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    if epoch%100==0:\n",
    "        print(f'epoch{epoch + 1}   ClusterNet value:{curr_test_loss}')\n",
    "        GCN_value.append(curr_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3544e8-879e-46f8-8352-aac27c36687e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2745811641216278,\n",
       " 0.7316926121711731,\n",
       " 0.7321180105209351,\n",
       " 0.7331862449645996,\n",
       " 0.7341327667236328,\n",
       " 0.7514181137084961,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131,\n",
       " 0.7533242702484131]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GCN_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5801e7e-552b-4cfc-ba24-f4749954ade7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
