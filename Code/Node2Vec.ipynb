{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f184032-bf05-4785-8193-8adbf0c30a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 92], x=[27, 3], y=[1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 27/27 [00:00<00:00, 11673.66it/s]\n",
      "\n",
      "Generating walks (CPU: 1):   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2):   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 3):   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:00<00:00, 54.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 5, Modularity: 0.6522\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "# 将边索引转换为 scipy 稀疏矩阵\n",
    "import community as community_louvain  # Louvain community detection\n",
    "from torch_geometric.datasets import Planetoid, TUDataset\n",
    "from torch_geometric.utils import to_dense_adj, to_scipy_sparse_matrix, from_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.algorithms import community\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "#-------------------------------------------------------\n",
    "#-------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "dataset = TUDataset(root='../tmp/Proteins', name='PROTEINS')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[1].to(device)\n",
    "print(data)\n",
    "edge_index = data.edge_index.cpu().numpy()\n",
    "num_nodes = data.num_nodes\n",
    "G = nx.Graph()#创建networkx的空图\n",
    "for i in range(num_nodes):\n",
    "    G.add_node(i, features=data.x[i].cpu().numpy())\n",
    "# 添加边\n",
    "for i, j in edge_index.T:\n",
    "    G.add_edge(i, j)\n",
    "# 使用Node2Vec生成节点嵌入\n",
    "node2vec = Node2Vec(G, dimensions=32, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "# 获取节点嵌入表示\n",
    "embeddings = [model.wv[str(node)] for node in G.nodes()]\n",
    "k=5\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# 创建节点与社区的映射\n",
    "node_cluster_map = {node: clusters[i] for i, node in enumerate(G.nodes())}\n",
    "\n",
    "# 将节点划分转换为社区列表\n",
    "communities_kmeans = []\n",
    "for community_id in set(node_cluster_map.values()):\n",
    "    communities_kmeans.append([node for node in node_cluster_map if node_cluster_map[node] == community_id])\n",
    "\n",
    "# 计算模块度\n",
    "modularity_kmeans = community.modularity(G, communities_kmeans)\n",
    "print(f\"Number of clusters: {k}, Modularity: {modularity_kmeans:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42942aec-6f44-495e-b50f-97674a8db574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 2708/2708 [00:00<00:00, 5652.63it/s]\n",
      "/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 1):   0%|          | 0/50 [00:00<?, ?it/s]/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 2):   0%|          | 0/50 [00:00<?, ?it/s]/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 3):   0%|          | 0/50 [00:00<?, ?it/s]/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [01:36<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 7, Modularity: 0.7426\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='../tmp/Cora', name='Cora')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "print(data)\n",
    "edge_index = data.edge_index.cpu().numpy()\n",
    "num_nodes = data.num_nodes\n",
    "G = nx.Graph()#创建networkx的空图\n",
    "for i in range(num_nodes):\n",
    "    G.add_node(i, features=data.x[i].cpu().numpy())\n",
    "# 添加边\n",
    "for i, j in edge_index.T:\n",
    "    G.add_edge(i, j)\n",
    "# 使用Node2Vec生成节点嵌入\n",
    "node2vec = Node2Vec(G, dimensions=32, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "# 获取节点嵌入表示\n",
    "embeddings = [model.wv[str(node)] for node in G.nodes()]\n",
    "k=7\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# 创建节点与社区的映射\n",
    "node_cluster_map = {node: clusters[i] for i, node in enumerate(G.nodes())}\n",
    "\n",
    "# 将节点划分转换为社区列表\n",
    "communities_kmeans = []\n",
    "for community_id in set(node_cluster_map.values()):\n",
    "    communities_kmeans.append([node for node in node_cluster_map if node_cluster_map[node] == community_id])\n",
    "\n",
    "# 计算模块度\n",
    "modularity_kmeans = community.modularity(G, communities_kmeans)\n",
    "print(f\"Number of clusters: {k}, Modularity: {modularity_kmeans:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6859af3-7648-4f65-ad67-74abede41921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----start to read node.-----------------------\n",
      "After adding package nodes: 380 nodes\n",
      "After adding app nodes: 1380 nodes\n",
      "After adding user nodes: 101380 nodes\n",
      "After adding cell nodes: 170380 nodes\n",
      "-----all nodes is read already.----------------\n",
      "----------start to read edge.----------------------\n",
      "----------1--------------------\n",
      "After first addition, number of edges: 1900000\n",
      "----------2--------------------\n",
      "After second addition, number of edges: 8800000\n",
      "----------3--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After third addition, number of edges: 8900000\n",
      "---------all edge is read already.------------------\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "\n",
    "##----------read nodes function-------------------------------------\n",
    "def read_nodes(file_path, node_type):\n",
    "    with open(file_path, 'r') as file:\n",
    "        nodes = [line.strip() for line in file]\n",
    "    node_data = {}\n",
    "    for node_str in nodes:\n",
    "        node_parts = node_str.split(',')\n",
    "        node_id = node_type + node_parts[0]\n",
    "        #features = list(map(float, node_parts[1:]))\n",
    "        features = ''  ##For common community detection algorithm,you don't need any features.\n",
    "        node_data[node_id] = {'node_type': node_type, 'features': features}\n",
    "    return node_data\n",
    "\n",
    "\n",
    "##--------------------------------------------------------------------\n",
    "\n",
    "\n",
    "##------------read edge function-----------------------------------------------\n",
    "def read_edges_incremental(file_path, edge_type, node_type_map):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            edge_str = line.strip()\n",
    "            edge_parts = edge_str.split(',')\n",
    "            node1 = node_type_map[0] + edge_parts[0]\n",
    "            node2 = node_type_map[1] + edge_parts[1]\n",
    "            #features = list(map(float, edge_parts[2:]))\n",
    "            features=''\n",
    "            node1_type = node_type_map[0]\n",
    "            node2_type = node_type_map[1]\n",
    "            yield (node1, node2,\n",
    "                   {'edge_type': edge_type, 'features': features})\n",
    "\n",
    "\n",
    "##---------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print(\"----start to read node.-----------------------\")\n",
    "app_nodes = read_nodes('telecom-graph//node_app.txt', 'app')\n",
    "package_nodes = read_nodes('telecom-graph//node_package.txt', 'package')\n",
    "user_nodes = read_nodes('telecom-graph//node_user.txt', 'user')\n",
    "cell_nodes = read_nodes('telecom-graph//node_cell.txt', 'cell')\n",
    "G = nx.Graph()\n",
    "# 添加 package 节点并输出节点数量\n",
    "for node_id, data in package_nodes.items():\n",
    "    G.add_node(node_id, **data)\n",
    "print(f\"After adding package nodes: {len(G.nodes())} nodes\")\n",
    "\n",
    "# 添加 app 节点并输出节点数量\n",
    "for node_id, data in app_nodes.items():\n",
    "    G.add_node(node_id, **data)\n",
    "print(f\"After adding app nodes: {len(G.nodes())} nodes\")\n",
    "\n",
    "# 添加 user 节点并输出节点数量\n",
    "for node_id, data in user_nodes.items():\n",
    "    G.add_node(node_id, **data)\n",
    "print(f\"After adding user nodes: {len(G.nodes())} nodes\")\n",
    "\n",
    "# 添加 cell 节点并输出节点数量\n",
    "for node_id, data in cell_nodes.items():\n",
    "    G.add_node(node_id, **data)\n",
    "print(f\"After adding cell nodes: {len(G.nodes())} nodes\")\n",
    "print(\"-----all nodes is read already.----------------\")\n",
    "\n",
    "print(\"----------start to read edge.----------------------\")\n",
    "\n",
    "print(\"----------1--------------------\")\n",
    "for edge in read_edges_incremental('telecom-graph//edge_user_buy_package.txt', 'buy',\n",
    "                                   ['user', 'package']):\n",
    "    G.add_edge(edge[0], edge[1], **edge[2])\n",
    "# 打印图的信息，检查是否添加了边\n",
    "print(f\"After first addition, number of edges: {G.number_of_edges()}\")\n",
    "# 进行垃圾回收，释放内存\n",
    "gc.collect()\n",
    "\n",
    "print(\"----------2--------------------\")\n",
    "for edge in read_edges_incremental('telecom-graph//edge_user_live_cell.txt', 'live',\n",
    "                                   ['user', 'cell']):\n",
    "    G.add_edge(edge[0], edge[1], **edge[2])\n",
    "\n",
    "# 进行垃圾回收，释放内存\n",
    "gc.collect()\n",
    "print(f\"After second addition, number of edges: {G.number_of_edges()}\")\n",
    "print(\"----------3--------------------\")\n",
    "for edge in read_edges_incremental('telecom-graph//edge_user_use_app.txt', 'use',\n",
    "                                   ['user', 'app']):\n",
    "    G.add_edge(edge[0], edge[1], **edge[2])\n",
    "\n",
    "# 进行垃圾回收，释放内存\n",
    "gc.collect()\n",
    "print(f\"After third addition, number of edges: {G.number_of_edges()}\")\n",
    "print(\"---------all edge is read already.------------------\")\n",
    "\n",
    "#nx.write_graphml(G, \"telecom_network_1.graphml\")\n",
    "#print(\"Writing done!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5ca4e-b394-48e4-a412-ed574178199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_components = list(nx.connected_components(G))\n",
    "G = G.subgraph(connected_components[0])\n",
    "# 使用Node2Vec生成节点嵌入\n",
    "node2vec = Node2Vec(G, dimensions=4, walk_length=1, num_walks=5, workers=8)\n",
    "model = node2vec.fit(window=5, min_count=1, batch_words=4)\n",
    "# 获取节点嵌入表示\n",
    "embeddings = [model.wv[str(node)] for node in G.nodes()]\n",
    "k=35\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# 创建节点与社区的映射\n",
    "node_cluster_map = {node: clusters[i] for i, node in enumerate(G.nodes())}\n",
    "\n",
    "# 将节点划分转换为社区列表\n",
    "communities_kmeans = []\n",
    "for community_id in set(node_cluster_map.values()):\n",
    "    communities_kmeans.append([node for node in node_cluster_map if node_cluster_map[node] == community_id])\n",
    "\n",
    "# 计算模块度\n",
    "modularity_kmeans = community.modularity(G, communities_kmeans)\n",
    "print(f\"Number of clusters: {k}, Modularity: {modularity_kmeans:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4156101e-3b73-455c-89f9-f0480866ea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 19717/19717 [00:00<00:00, 162523.79it/s]\n",
      "/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 1):  28%|██▊       | 14/50 [00:00<00:02, 14.50it/s]/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 1):  56%|█████▌    | 28/50 [00:01<00:01, 14.06it/s]/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 2):  56%|█████▌    | 28/50 [00:01<00:01, 14.14it/s]/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:03<00:00, 14.44it/s]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 3, Modularity: 0.4761\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='../tmp/Pubmed', name='Pubmed')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "print(data)\n",
    "dge_index = data.edge_index.cpu().numpy()\n",
    "num_nodes = data.num_nodes\n",
    "G = nx.Graph()#创建networkx的空图\n",
    "for i in range(num_nodes):\n",
    "    G.add_node(i, features=data.x[i].cpu().numpy())\n",
    "# 添加边\n",
    "for i, j in edge_index.T:\n",
    "    G.add_edge(i, j)\n",
    "# 使用Node2Vec生成节点嵌入\n",
    "node2vec = Node2Vec(G, dimensions=32, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "# 获取节点嵌入表示\n",
    "embeddings = [model.wv[str(node)] for node in G.nodes()]\n",
    "k=3\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# 创建节点与社区的映射\n",
    "node_cluster_map = {node: clusters[i] for i, node in enumerate(G.nodes())}\n",
    "\n",
    "# 将节点划分转换为社区列表\n",
    "communities_kmeans = []\n",
    "for community_id in set(node_cluster_map.values()):\n",
    "    communities_kmeans.append([node for node in node_cluster_map if node_cluster_map[node] == community_id])\n",
    "\n",
    "# 计算模块度\n",
    "modularity_kmeans = community.modularity(G, communities_kmeans)\n",
    "print(f\"Number of clusters: {k}, Modularity: {modularity_kmeans:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8941a1ec-1071-49ce-a943-c234e49090c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citeseer()\n",
      "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 3327/3327 [00:00<00:00, 151045.07it/s]\n",
      "/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 1):  38%|███▊      | 19/50 [00:00<00:00, 37.19it/s]/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 1):  54%|█████▍    | 27/50 [00:00<00:00, 38.55it/s]/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 3):  12%|█▏        | 6/50 [00:00<00:00, 48.57it/s]/home/ma-user/anaconda3/envs/PyTorch-1.8/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:01<00:00, 38.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 7, Modularity: 0.6562\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='../tmp/Citeseer', name='Citeseer')\n",
    "print(dataset)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "print(data)\n",
    "dge_index = data.edge_index.cpu().numpy()\n",
    "num_nodes = data.num_nodes\n",
    "G = nx.Graph()#创建networkx的空图\n",
    "for i in range(num_nodes):\n",
    "    G.add_node(i, features=data.x[i].cpu().numpy())\n",
    "# 添加边\n",
    "for i, j in edge_index.T:\n",
    "    G.add_edge(i, j)\n",
    "# 使用Node2Vec生成节点嵌入\n",
    "node2vec = Node2Vec(G, dimensions=32, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "# 获取节点嵌入表示\n",
    "embeddings = [model.wv[str(node)] for node in G.nodes()]\n",
    "k=7\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# 创建节点与社区的映射\n",
    "node_cluster_map = {node: clusters[i] for i, node in enumerate(G.nodes())}\n",
    "\n",
    "# 将节点划分转换为社区列表\n",
    "communities_kmeans = []\n",
    "for community_id in set(node_cluster_map.values()):\n",
    "    communities_kmeans.append([node for node in node_cluster_map if node_cluster_map[node] == community_id])\n",
    "\n",
    "# 计算模块度\n",
    "modularity_kmeans = community.modularity(G, communities_kmeans)\n",
    "print(f\"Number of clusters: {k}, Modularity: {modularity_kmeans:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "472dd7af-9856-43ba-9565-f663089d6da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[7600, 932], edge_index=[2, 30019], y=[7600], train_mask=[7600, 10], val_mask=[7600, 10], test_mask=[7600, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 7600/7600 [00:00<00:00, 160587.15it/s]\n",
      "\n",
      "Generating walks (CPU: 1):  18%|█▊        | 9/50 [00:00<00:01, 34.46it/s]\n",
      "Generating walks (CPU: 1):  42%|████▏     | 21/50 [00:00<00:00, 29.08it/s]\n",
      "Generating walks (CPU: 2):  42%|████▏     | 21/50 [00:00<00:00, 29.87it/s]\n",
      "Generating walks (CPU: 4): 100%|██████████| 50/50 [00:01<00:00, 26.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 3, Modularity: 0.4761\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import  Actor\n",
    "dataset =  Actor(root='../tmp/Actor')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = dataset[0].to(device)\n",
    "print(data)\n",
    "dge_index = data.edge_index.cpu().numpy()\n",
    "num_nodes = data.num_nodes\n",
    "G = nx.Graph()#创建networkx的空图\n",
    "for i in range(num_nodes):\n",
    "    G.add_node(i, features=data.x[i].cpu().numpy())\n",
    "# 添加边\n",
    "for i, j in edge_index.T:\n",
    "    G.add_edge(i, j)\n",
    "# 使用Node2Vec生成节点嵌入\n",
    "node2vec = Node2Vec(G, dimensions=32, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "# 获取节点嵌入表示\n",
    "embeddings = [model.wv[str(node)] for node in G.nodes()]\n",
    "k=3\n",
    "kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# 创建节点与社区的映射\n",
    "node_cluster_map = {node: clusters[i] for i, node in enumerate(G.nodes())}\n",
    "\n",
    "# 将节点划分转换为社区列表\n",
    "communities_kmeans = []\n",
    "for community_id in set(node_cluster_map.values()):\n",
    "    communities_kmeans.append([node for node in node_cluster_map if node_cluster_map[node] == community_id])\n",
    "\n",
    "# 计算模块度\n",
    "modularity_kmeans = community.modularity(G, communities_kmeans)\n",
    "print(f\"Number of clusters: {k}, Modularity: {modularity_kmeans:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5de3e7-1d12-448d-80ff-aa6e1bae9a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.8",
   "language": "python",
   "name": "pytorch-1.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
